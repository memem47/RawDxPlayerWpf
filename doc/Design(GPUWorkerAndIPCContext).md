# README / è¨­è¨ˆæ›¸

## GPU Worker + IPC Context è¨­è¨ˆï¼ˆSingle-thread GPU Executorï¼‰
### ç›®çš„

æœ¬ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ã€**D3D11 / CUDA interop ã‚’å«ã‚€ GPU å‡¦ç†ã‚’ã€Œå¿…ãšåŒä¸€ã‚¹ãƒ¬ãƒƒãƒ‰ã§ç›´åˆ—å®Ÿè¡Œã€**ã™ã‚‹ãŸã‚ã®åŸºç›¤ã‚’æä¾›ã™ã‚‹ã€‚

- GPU API ã¯ã€Œå‘¼ã³å‡ºã—ã‚¹ãƒ¬ãƒƒãƒ‰åˆ¶ç´„ã€ã‚„ã€ŒåŒæ™‚ã‚¢ã‚¯ã‚»ã‚¹åˆ¶ç´„ã€ãŒå¼·ã„

- UI ã‚¹ãƒ¬ãƒƒãƒ‰ / ä»»æ„ã‚¹ãƒ¬ãƒƒãƒ‰ã‹ã‚‰ã®å‘¼ã³å‡ºã—ã‚’è¨±å®¹ã—ã¤ã¤ã€GPU å´ã¯ å˜ä¸€ã‚¹ãƒ¬ãƒƒãƒ‰ã«é–‰ã˜è¾¼ã‚ã‚‹

- å‘¼ã³å‡ºã—å´ã«ã¯åŒæœŸ APIï¼ˆSubmitAndWaitï¼‰ã‚’æä¾›ã—ã€å®Ÿè¡Œã®æˆå¦ã¯ int32_t ã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰ã§è¿”ã™

### ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆæ¦‚è¦
#### GpuWorkerï¼ˆsingle-thread executorï¼‰

- ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰ 1 æœ¬ã‚’ç”Ÿæˆã—ã€ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ï¼ˆFIFOï¼‰ã«å…¥ã£ãŸã‚¸ãƒ§ãƒ–ã‚’ ç›´åˆ—å®Ÿè¡Œã™ã‚‹ã€‚

- SubmitAndWait(fn) ã¯

1. å¿…è¦ãªã‚‰ã‚¹ãƒ¬ãƒƒãƒ‰èµ·å‹•
2. packaged_task ã¨ future ã§ã‚¸ãƒ§ãƒ–ã‚’ enqueue
3. notify_one() ã§èµ·åºŠ
4. future.get() ã§å®Œäº†ã¾ã§å¾…æ©Ÿ
ã‚’è¡Œã†ã€‚

- condition_variable::wait(lock, pred) ã‚’ä½¿ç”¨ã—ã€ã‚¹ãƒ—ãƒªã‚¢ã‚¹ã‚¦ã‚§ã‚¤ã‚¯ã‚¢ãƒƒãƒ—ã«å¯¾ã—ã¦å®‰å…¨ã«å¾…æ©Ÿã™ã‚‹ã€‚

#### IpcContextï¼ˆGPU thread-owned stateï¼‰

- D3D11 ãƒ‡ãƒã‚¤ã‚¹/ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€IO ãƒªã‚½ãƒ¼ã‚¹ï¼ˆshared texture / bufferï¼‰ã€stagingã€CUDA interop ç™»éŒ²ãƒãƒ³ãƒ‰ãƒ«ã‚’ä¿æŒã™ã‚‹ã€‚

- æ‰€æœ‰è€…ã¯ GPU worker ã‚¹ãƒ¬ãƒƒãƒ‰ã®ã¿ã€‚ä»–ã‚¹ãƒ¬ãƒƒãƒ‰ã‹ã‚‰ç›´æ¥è§¦ã‚Œãªã„ï¼ˆãƒ‡ãƒ¼ã‚¿ç«¶åˆãƒ»ä¸æ­£ãª API å‘¼ã³å‡ºã—ã‚’é˜²ãï¼‰ã€‚

- Reset() ã¯ CUDA interop ã®è§£é™¤ï¼ˆunregisterï¼‰â†’ CUDA ã‚­ãƒ£ãƒƒã‚·ãƒ¥è§£æ”¾ â†’ D3D ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾ã®é †ã§è¡Œã„ã€å†åˆæœŸåŒ–ã®å‰æçŠ¶æ…‹ã«æˆ»ã™ã€‚

### ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ»æ‰€æœ‰æ¨©ï¼ˆé‡è¦ï¼‰

- g_ctxï¼ˆIpcContextï¼‰ã¯ GPU worker ã‚¹ãƒ¬ãƒƒãƒ‰ã®å°‚æœ‰ç‰©ã€‚
- D3D11/CUDA interop ã¯ã€Œç™»éŒ²ãƒ»map/unmapãƒ»è§£é™¤ã€ã®é †åºã‚„ã€å¯¾è±¡ãƒ‡ãƒã‚¤ã‚¹ã®åˆ¶ç´„ãŒã‚ã‚‹ãŸã‚ã€ç™»éŒ²ã•ã‚ŒãŸãƒªã‚½ãƒ¼ã‚¹ã¯è§£é™¤ã¾ã§ç”Ÿå­˜ã•ã›ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚
- GpuWorker::Stop() ã¯ã€Œstop ãƒ•ãƒ©ã‚°è¨­å®š â†’ notify â†’ joinã€ã§ã€ã‚­ãƒ¥ãƒ¼ãŒç©ºã«ãªã‚‹ã¾ã§å®Ÿè¡Œã—ã¦ã‹ã‚‰åœæ­¢ã™ã‚‹ï¼ˆå®‰å…¨ãªã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³ï¼‰ã€‚

### å…¸å‹çš„ãªå‘¼ã³å‡ºã—ãƒ•ãƒ­ãƒ¼

1. ï¼ˆå‘¼ã³å‡ºã—å…ƒã‚¹ãƒ¬ãƒƒãƒ‰ï¼‰SubmitAndWait([&]{ ... GPUå‡¦ç† ... })
2. ï¼ˆGPU workerï¼‰å¿…è¦ãªã‚‰ g_ctx åˆæœŸåŒ–ï¼ˆdevice/context ä½œæˆã€IO/staging ä½œæˆã€CUDA interop ç™»éŒ²ï¼‰
3. ï¼ˆGPU workerï¼‰map â†’ kernel / copy â†’ unmap
4. ï¼ˆå‘¼ã³å‡ºã—å…ƒã‚¹ãƒ¬ãƒƒãƒ‰ï¼‰æˆ»ã‚Šå€¤ï¼ˆint32_tï¼‰ã§æˆåŠŸ/å¤±æ•—ã‚’åˆ¤æ–­

### ã‚¨ãƒ©ãƒ¼ãƒ»ä¾‹å¤–ãƒãƒªã‚·ãƒ¼

- GPU ã‚¹ãƒ¬ãƒƒãƒ‰ä¸Šã®ã‚¸ãƒ§ãƒ–ã¯ ä¾‹å¤–ã‚’æŠ•ã’ãªã„ï¼ˆC API / P/Invoke å¢ƒç•Œã‚’æƒ³å®šï¼‰ã€‚
- å¤±æ•—ã¯ã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰ï¼ˆint32_tï¼‰ã§è¿”ã—ã€å¿…è¦ã«å¿œã˜ã¦ãƒ­ã‚°å‡ºåŠ›ã™ã‚‹ã€‚

### åˆ¶ç´„ãƒ»æ³¨æ„ç‚¹ï¼ˆPitfallsï¼‰

- SubmitAndWait() ã¯åŒæœŸ API ãªã®ã§ã€å¤šç”¨ã™ã‚‹ã¨å‘¼ã³å‡ºã—å…ƒã‚’ãƒ–ãƒ­ãƒƒã‚¯ã™ã‚‹ï¼ˆUI ã‚¹ãƒ¬ãƒƒãƒ‰ã‹ã‚‰ã®é€£æ‰“ã«æ³¨æ„ï¼‰ã€‚
- Stop() ã¯ DLL unload / ãƒ—ãƒ­ã‚»ã‚¹çµ‚äº†å‰ã«å¿…ãšå‘¼ã¶ï¼ˆGPU ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾ã¨ã‚¹ãƒ¬ãƒƒãƒ‰çµ‚äº†é †åºãŒå´©ã‚Œã‚‹ã¨ã‚¯ãƒ©ãƒƒã‚·ãƒ¥è¦å› ï¼‰ã€‚
- D3D11 interop ãƒªã‚½ãƒ¼ã‚¹ã¯ cudaGraphicsD3D11RegisterResource â†’ map/unmap â†’ cudaGraphicsUnregisterResource ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ã‚’å®ˆã‚‹ã€‚

### å‚è€ƒæ–‡çŒ®ï¼ˆä¸€æ¬¡æƒ…å ±ä¸­å¿ƒï¼‰

- C++ std::condition_variable::waitï¼ˆè¿°èªä»˜ã wait ã¨ã‚¹ãƒ—ãƒªã‚¢ã‚¹ã‚¦ã‚§ã‚¤ã‚¯ã‚¢ãƒƒãƒ—ï¼‰
- NVIDIA CUDA Runtime API: Direct3D 11 Interoperabilityï¼ˆD3D11-CUDA interopï¼‰
- cudaGraphicsD3D11RegisterResource / unregister ã®èª¬æ˜ï¼ˆç™»éŒ²ã«ã‚ˆã‚Šå‚ç…§ã‚«ã‚¦ãƒ³ãƒˆãŒå¢—ãˆã‚‹ç­‰ï¼‰

## cudaMallocAsync + stream çµ±ä¸€ç‰ˆã¸ã®æ‹¡å¼µã‚³ãƒ¡ãƒ³ãƒˆï¼ˆå·®ã—è¾¼ã¿ç”¨ï¼‰

ã“ã“ã‹ã‚‰ã¯ã€ŒCudaInterop å´ã‚’ Context åŒ–ã—ã€cudaMallocAsync/cudaFreeAsync ã¨ å˜ä¸€ streamï¼ˆä¾‹: cudaStream_t stream;ï¼‰ã§çµ±ä¸€ã™ã‚‹ã€å‰æã§ã€**ã‚³ãƒ¼ãƒ‰ã«è¿½åŠ ã™ã¹ãâ€œè£½å“ãƒ¬ãƒ™ãƒ«ã®ã‚³ãƒ¡ãƒ³ãƒˆâ€**ã§ã™ã€‚

### 2-1. è¨­è¨ˆæ–¹é‡ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã¨ã—ã¦å…¥ã‚Œã‚‹ã¹ãè¦ç‚¹ï¼‰
#### A) â€œStream-ordered allocatorâ€ ã®å‰æã‚’æ˜ç¤ºã™ã‚‹

cudaMallocAsync ã¯ stream é †åºã§ allocate/free ãŒæˆç«‹ã™ã‚‹ãŸã‚ã€ã‚¢ã‚¯ã‚»ã‚¹é †åºã‚’ç ´ã‚‹ã¨æœªå®šç¾©å‹•ä½œï¼ˆuse-after-free ç­‰ï¼‰ã«ãªã‚‹ã€‚

ã•ã‚‰ã«ã€å¾“æ¥ã® cudaMalloc/cudaFree ã¯å…¨ã‚¹ãƒˆãƒªãƒ¼ãƒ åŒæœŸã‚’å¼•ãèµ·ã“ã—å¾—ã‚‹ãŒã€stream-ordered allocator ã¯ã“ã‚Œã‚’å›é¿ã—ã‚„ã™ã„ã€‚

ğŸ‘‰ ãªã®ã§ã‚³ãƒ¡ãƒ³ãƒˆã«ã“ã†æ›¸ãï¼ˆè¦æ—¨ï¼‰ï¼š

- ã€Œã“ã®ãƒã‚¤ãƒ³ã‚¿ã¯ ã“ã® stream ä¸Šã® work ã«ã®ã¿é–¢é€£ä»˜ã‘ã‚‰ã‚Œã¦ã„ã‚‹ã€
- ã€Œfree ã¯ cudaFreeAsync(ptr, stream) ã‚’ä½¿ã„ã€åŒä¸€ stream ã®é †åºä¿è¨¼ã«ä¾å­˜ã™ã‚‹ã€
- ã€Œä»– stream / host ã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’æ··ãœãªã„ã€

#### B) â€œ1 worker thread = 1 CUDA streamâ€ ã‚’ä¸å¤‰æ¡ä»¶ã¨ã—ã¦å®£è¨€ã™ã‚‹

GPU worker ã¯ãã‚‚ãã‚‚ single-thread executor ãªã®ã§ã€
- GPU worker thread ã®ä¸­ã ã‘ã§ stream ã‚’ä½œã‚‹
- ãã® stream ã¯ CudaContext ã«ä¿æŒã—ã€å…¨ã‚«ãƒ¼ãƒãƒ«/ã‚³ãƒ”ãƒ¼/alloc/free ã‚’ãã“ã¸æµã™

ğŸ‘‰ ã‚³ãƒ¡ãƒ³ãƒˆã«ã“ã†æ›¸ãï¼ˆè¦æ—¨ï¼‰ï¼š

- ã€Œstream ã¯ GPU worker ã‚¹ãƒ¬ãƒƒãƒ‰ã«æŸç¸›ã•ã‚Œã‚‹ï¼ˆä½œæˆ/ç ´æ£„/ä½¿ç”¨ã¯åŒã‚¹ãƒ¬ãƒƒãƒ‰ã®ã¿ï¼‰ã€
- ã€Œstream ã‚’è·¨ãåŒæœŸã¯ï¼ˆåŸºæœ¬ï¼‰å…¥ã‚Œãªã„ã€‚å¿…è¦ãªã‚‰ event ã«çµ±ä¸€ã™ã‚‹ã€

### C) free ã®å‰ã« â€œã‚¢ã‚¯ã‚»ã‚¹å®Œäº†â€ ã‚’å‘¼ã³å‡ºã—å´ãŒä¿è¨¼ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ç‚¹

CUDA Runtime API ã®ãƒ¡ãƒ¢ãƒªç®¡ç†ã§ã¯ã€cudaFree/cudaFreeAsync å‘¼ã³å‡ºã—å‰ã«ã€Œå½“è©²ãƒ¡ãƒ¢ãƒªã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒå®Œäº†ã—ã¦ã„ã‚‹ã“ã¨ã€ã‚’å‘¼ã³å‡ºã—å´ãŒä¿è¨¼ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€ã¨ã„ã†æ³¨æ„ãŒã‚ã‚‹ï¼ˆç‰¹ã« async allocator é–¢é€£ï¼‰ã€‚

â†’ è¨­è¨ˆã¨ã—ã¦ã¯ã€ŒåŒä¸€ stream ã«è¼‰ã›ã‚‹ã€ã“ã¨ã§é †åºä¿è¨¼ã‚’æˆç«‹ã•ã›ã‚‹ã®ãŒç­‹ã€‚

### 2-2. å…·ä½“çš„ã«å·®ã—è¾¼ã‚€ã‚³ãƒ¡ãƒ³ãƒˆä¾‹ï¼ˆIpcContext / CudaInterop å´ï¼‰
#### IpcContext å´ã«è¿½åŠ ã™ã‚‹ãªã‚‰ï¼ˆä¾‹ï¼‰
```dcpp
// CUDA execution stream (created and used ONLY on the GPU worker thread)
//
// DESIGN INVARIANT:
//  - All CUDA work (kernels, async copies, interop map/unmap sequencing,
//    and stream-ordered allocations) must be issued to this single stream.
//  - This guarantees ordering without cross-stream synchronization.
//  - Do NOT access stream-ordered allocations from any other stream.
//
// RATIONALE:
//  - cudaMalloc/cudaFree may introduce device-wide synchronization,
//    while stream-ordered allocator (cudaMallocAsync/cudaFreeAsync)
//    enables allocation/free to be ordered with work in this stream.  (see refs)
cudaStream_t stream = nullptr;
```
#### CudaInterop ã® â€œContext åŒ–â€ã‚¯ãƒ©ã‚¹ã®å…ˆé ­ã‚³ãƒ¡ãƒ³ãƒˆï¼ˆä¾‹ï¼‰
```cpp
/*
 * CudaContext (GPU-worker-thread owned)
 *
 * Owns:
 *  - a dedicated cudaStream_t for all CUDA work
 *  - (optional) a cudaMemPool_t configuration if customizing pool behavior
 *
 * Stream-Ordered Allocator Policy:
 *  - Use cudaMallocAsync/cudaFreeAsync on this stream ONLY.
 *  - Any access to async-allocated memory MUST occur between the
 *    stream-ordered allocation and free operations; otherwise undefined behavior.
 *
 * Threading:
 *  - Create/destroy/use only on the GPU worker thread.
 */
```
#### CudaReleaseCache() ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’ â€œmallocAsync å‰æâ€ã«æ›´æ–°
```cpp
// Release allocator/cache resources associated with stream-ordered allocations.
//
// NOTE:
//  - With cudaMallocAsync, the allocator uses a memory pool.
//  - Cache release should be done only after the stream has been drained
//    (i.e., no outstanding work that may touch pooled allocations).
//  - Do NOT call from non-GPU threads.
```
### 2-3. â€œçµ±ä¸€ streamâ€ ã‚’å‰æã«ã—ãŸé‹ç”¨ãƒ«ãƒ¼ãƒ«ï¼ˆREADME ã«è¿½è¨˜æ¨å¥¨ï¼‰

- interop ã® map/unmapã€ã‚«ãƒ¼ãƒãƒ«ã€copyã€alloc/free ã¯ ã™ã¹ã¦åŒä¸€ stream ã«æŠ•å…¥ã™ã‚‹
- CPU å´ã§çµæœãŒå¿…è¦ãªå¢ƒç•Œï¼ˆSubmitAndWait ã®æˆ»ã‚Šï¼‰ã§ã¯ã€å¿…è¦ã«å¿œã˜ã¦ stream åŒæœŸï¼ˆä¾‹: cudaStreamSynchronize(stream) ã‚‚ã—ãã¯ event waitï¼‰
- cudaFreeAsync ã¯ åŒä¸€ stream ä¸Šã®é †åºä¿è¨¼ã«ä¾å­˜ã™ã‚‹ãŸã‚ã€åˆ¥ stream ã§è§¦ã‚‹è¨­è¨ˆã«ã—ãªã„ï¼ˆæœªå®šç¾©å‹•ä½œãƒªã‚¹ã‚¯ï¼‰