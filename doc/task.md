# CUDA 最適化・設計改善の今後の課題まとめ

このドキュメントは、CUDA ベースの画像処理コードを製品レベルへ発展させるための改善ポイントを整理したものです。

---

## 1. Block サイズ最適化

### ● 概要
CUDA カーネルの `dim3 block(x, y)` は性能に大きく影響する。  
`16×16` は汎用的だが最適とは限らない。

### ● 調整の目的
- メモリアクセス効率の向上  
- warp（32 threads）効率の改善  
- occupancy（SM の稼働率）の向上  
- レジスタ使用量とのバランス調整  

### ● 調整の基準
- GPU の世代・SM 構成  
- カーネルのレジスタ使用量  
- メモリ帯域依存か計算依存か  
- Nsight Compute による実測プロファイル  

### ● 試すべき block サイズ例
- 8×8  
- 16×16（基準）  
- 32×8  
- 32×16  
- 32×32（最大 1024 threads/block）

---

## 2. スレッドセーフ化

### ● 課題
グローバル変数（例：`g_midBuf`）を複数スレッドが共有すると競合が発生する。

### ● 対策案
- `std::mutex` による排他制御  
- グローバル変数を廃止し、インスタンスごとにバッファを持つ設計へ変更  
- CUDA の stream と `cudaMallocAsync` を併用して非同期メモリ管理を行う  

---

## 3. cudaMallocAsync / cudaFreeAsync の活用

### ● 概要
CUDA 11 以降で利用可能な非同期メモリ確保 API。

### ● メリット
- GPU 全体を同期しないため高速  
- メモリプールにより確保/解放が軽量  
- スレッドセーフ性が向上（stream 単位で独立）

### ● 注意点
- CUDA 11+ が必要  
- stream 管理が必要になる  

---

## 4. バッファ切り替えロジックの RAII 化

### ● 課題
`io` と `g_midBuf` の切り替えを手動で管理しており、  
途中 return で状態が壊れる可能性がある。

### ● 解決案（RAII）
- バッファ切り替えをクラス化し、  
  コンストラクタで初期化、デストラクタで後始末を自動化する。

### ● メリット
- 例外・早期 return に強い  
- コードの安全性と可読性が向上  

---

## 5. カーネル起動の共通化（テンプレート化）

### ● 課題
カーネル起動コードが重複している。

### ● 解決案
テンプレート関数で launch を共通化する。

### ● メリット
- コード量削減  
- エラー処理の一元化  
- メンテナンス性向上  

---

## 6. 処理パイプラインの抽象化

### ● 課題
処理ステージが手続き的に書かれており拡張性が低い。

### ● 解決案
- 各処理（Sobel, Blur, Invert, Threshold）を「ステージ」としてクラス化  
- ベクタに積んで順番に実行するパイプライン方式へ

### ● メリット
- 新しい処理の追加が容易  
- 条件分岐が減り読みやすい  
- テストしやすい構造になる  

---

## 7. Shared Memory の活用

### ● 概要
ブロック内のスレッドが共有できる高速メモリ（L1 キャッシュ並）。

### ● 利用目的
- グローバルメモリのアクセス回数削減  
- 画像処理（3×3 フィルタなど）で大幅な高速化  
- メモリアクセスの整列性向上  

### ● 注意点
- 容量が小さい（48〜100KB/SM）  
- ブロックサイズと shared memory 使用量のバランスが必要  

---

## まとめ

| 項目 | 目的 |
|------|------|
| Block サイズ最適化 | GPU の性能を最大限引き出す |
| スレッドセーフ化 | 複数スレッド環境での安定動作 |
| cudaMallocAsync | 高速・安全なメモリ管理 |
| RAII 化 | バッファ管理の安全性向上 |
| カーネル起動共通化 | コードの簡潔化・保守性向上 |
| パイプライン抽象化 | 拡張性・再利用性の向上 |
| Shared Memory 活用 | 画像処理の高速化 |

---

このドキュメントは、CUDA コードを製品レベルへ進化させるための改善ポイントを俯瞰できるようにまとめたものです。
